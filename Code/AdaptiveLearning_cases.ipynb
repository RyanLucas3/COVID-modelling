{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class ModelGroupSpecs:\n",
    "    def __init__(self, ar_orders, desired_model_groups):\n",
    "        self.ar_orders = ar_orders\n",
    "        self.desired_model_groups = desired_model_groups\n",
    "\n",
    "    def get_all_possible_combinations(self, model_group, MG_ar_orders, MG_regressors):\n",
    "        return list(product(model_group, MG_ar_orders, MG_regressors))\n",
    "\n",
    "    def create_functional_sets(self):\n",
    "        output = []\n",
    "        if \"AR\" in self.desired_model_groups:\n",
    "            # MG1 = Model Group 1: AR models.\n",
    "\n",
    "            self.AR_models = self.get_all_possible_combinations(\n",
    "                model_group=['AR'],\n",
    "                MG_ar_orders=self.ar_orders,\n",
    "                MG_regressors=[None])\n",
    "            output.append(self.AR_models)\n",
    "\n",
    "        if \"OLS\" in self.desired_model_groups:\n",
    "            # MG2N = Model Group 2N: Single Variable Exogenous OLS\n",
    "\n",
    "            self.OLS_models = self.get_all_possible_combinations(\n",
    "                model_group=['OLS'],\n",
    "                MG_ar_orders=[None],#'log_new_vaccines_per_capita\t', \n",
    "                MG_regressors=['log_new_people_vaccinated_per_capita', \n",
    "                                'delta_cases_per_capita_United_Kingdom', 'delta_cases_per_capita_Germany', 'delta_cases_per_capita_France',\n",
    "                                'full_lockdown', 'full_lockdown.l30', 'full_lockdown.l45',\n",
    "                                'max_tp', 'min_tp', 'rain', 'humidity',\n",
    "                                'day_of_the_week', 'season', 'trend'])\n",
    "            output.append(self.OLS_models)\n",
    "\n",
    "\n",
    "        if \"ARX\" in self.desired_model_groups:\n",
    "            # MG2T and MG3T: Introducing lagged dependent terms to the previous model specifications.\n",
    "\n",
    "            self.ARX_models = self.get_all_possible_combinations(\n",
    "                model_group=['ARX'],\n",
    "                MG_ar_orders=self.ar_orders,\n",
    "                MG_regressors=['log_new_people_vaccinated_per_capita', \n",
    "                                'delta_cases_per_capita_United_Kingdom', 'delta_cases_per_capita_Germany', 'delta_cases_per_capita_France',\n",
    "                                'full_lockdown', 'full_lockdown.l30', 'full_lockdown.l45',\n",
    "                                'max_tp', 'min_tp', 'rain', 'humidity',\n",
    "                                'day_of_the_week', 'season', 'trend'])\n",
    "            output.append(self.ARX_models)\n",
    "\n",
    "        # Returning the functional sets to be deployed.\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "ar_orders = [1,2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "models = ModelGroupSpecs(ar_orders, ['AR', \"OLS\", \"ARX\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model_groups = models.create_functional_sets()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "combined = pd.read_csv(\"Data/Combined_Dataset.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "combined"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_deaths_per_capita</th>\n",
       "      <th>delta_cases_per_capita</th>\n",
       "      <th>delta_deaths_per_capita.l1</th>\n",
       "      <th>delta_cases_per_capita.l1</th>\n",
       "      <th>log_new_vaccines_per_capita</th>\n",
       "      <th>log_new_people_vaccinated_per_capita</th>\n",
       "      <th>delta_cases_per_capita_United_Kingdom</th>\n",
       "      <th>delta_deaths_per_capita_United Kingdom</th>\n",
       "      <th>...</th>\n",
       "      <th>full_lockdown</th>\n",
       "      <th>full_lockdown.l30</th>\n",
       "      <th>full_lockdown.l45</th>\n",
       "      <th>max_tp</th>\n",
       "      <th>min_tp</th>\n",
       "      <th>rain</th>\n",
       "      <th>humidity</th>\n",
       "      <th>day_of_the_week</th>\n",
       "      <th>season</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.650000e+00</td>\n",
       "      <td>1.65000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.864491e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>7.750000e-01</td>\n",
       "      <td>2.15625</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.006862e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.063675e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3750</td>\n",
       "      <td>2.162500e+00</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>1.2875</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.027447e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.006862e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.210287e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>0.50625</td>\n",
       "      <td>-0.9625</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.027447e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.184001e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.7875</td>\n",
       "      <td>-9.250000e-01</td>\n",
       "      <td>2.36250</td>\n",
       "      <td>-1.2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.213827e-04</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>3.259144e-04</td>\n",
       "      <td>2.693943e-10</td>\n",
       "      <td>1.112052e-10</td>\n",
       "      <td>5.728728e-04</td>\n",
       "      <td>2.433764e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0375</td>\n",
       "      <td>8.612500e+00</td>\n",
       "      <td>4.76250</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.099436e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.213827e-04</td>\n",
       "      <td>1.482583e-10</td>\n",
       "      <td>1.046810e-10</td>\n",
       "      <td>6.327639e-04</td>\n",
       "      <td>2.726988e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.6250</td>\n",
       "      <td>6.212500e+00</td>\n",
       "      <td>4.56875</td>\n",
       "      <td>-0.5875</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>608</td>\n",
       "      <td>2021-10-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.952352e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.099436e-04</td>\n",
       "      <td>1.034203e-10</td>\n",
       "      <td>8.457030e-11</td>\n",
       "      <td>5.982660e-04</td>\n",
       "      <td>2.433764e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9250</td>\n",
       "      <td>5.450000e+00</td>\n",
       "      <td>10.87500</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>609</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.939470e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.952352e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.535053e-04</td>\n",
       "      <td>1.084931e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.8375</td>\n",
       "      <td>6.812500e+00</td>\n",
       "      <td>7.90000</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>610</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.729591e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.939470e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.828571e-04</td>\n",
       "      <td>5.864491e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>5.187500e+00</td>\n",
       "      <td>3.22000</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>611 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        date  delta_deaths_per_capita  delta_cases_per_capita  \\\n",
       "0             0  2020-03-01                      0.0            0.000000e+00   \n",
       "1             1  2020-03-02                      0.0            0.000000e+00   \n",
       "2             2  2020-03-03                      0.0            2.006862e-07   \n",
       "3             3  2020-03-04                      0.0            8.027447e-07   \n",
       "4             4  2020-03-05                      0.0            0.000000e+00   \n",
       "..          ...         ...                      ...                     ...   \n",
       "606         606  2021-10-28                      0.0            5.213827e-04   \n",
       "607         607  2021-10-29                      0.0            5.099436e-04   \n",
       "608         608  2021-10-30                      0.0            5.952352e-04   \n",
       "609         609  2021-10-31                      0.0            3.939470e-04   \n",
       "610         610  2021-11-01                      0.0            5.729591e-04   \n",
       "\n",
       "     delta_deaths_per_capita.l1  delta_cases_per_capita.l1  \\\n",
       "0                      0.000000               0.000000e+00   \n",
       "1                      0.000000               0.000000e+00   \n",
       "2                      0.000000               0.000000e+00   \n",
       "3                      0.000000               2.006862e-07   \n",
       "4                      0.000000               8.027447e-07   \n",
       "..                          ...                        ...   \n",
       "606                    0.000013               3.259144e-04   \n",
       "607                    0.000000               5.213827e-04   \n",
       "608                    0.000000               5.099436e-04   \n",
       "609                    0.000000               5.952352e-04   \n",
       "610                    0.000000               3.939470e-04   \n",
       "\n",
       "     log_new_vaccines_per_capita  log_new_people_vaccinated_per_capita  \\\n",
       "0                   0.000000e+00                          0.000000e+00   \n",
       "1                   0.000000e+00                          0.000000e+00   \n",
       "2                   0.000000e+00                          0.000000e+00   \n",
       "3                   0.000000e+00                          0.000000e+00   \n",
       "4                   0.000000e+00                          0.000000e+00   \n",
       "..                           ...                                   ...   \n",
       "606                 2.693943e-10                          1.112052e-10   \n",
       "607                 1.482583e-10                          1.046810e-10   \n",
       "608                 1.034203e-10                          8.457030e-11   \n",
       "609                 0.000000e+00                          0.000000e+00   \n",
       "610                 0.000000e+00                          0.000000e+00   \n",
       "\n",
       "     delta_cases_per_capita_United_Kingdom  \\\n",
       "0                             0.000000e+00   \n",
       "1                             5.864491e-07   \n",
       "2                             8.063675e-07   \n",
       "3                             8.210287e-07   \n",
       "4                             7.184001e-07   \n",
       "..                                     ...   \n",
       "606                           5.728728e-04   \n",
       "607                           6.327639e-04   \n",
       "608                           5.982660e-04   \n",
       "609                           5.535053e-04   \n",
       "610                           5.828571e-04   \n",
       "\n",
       "     delta_deaths_per_capita_United Kingdom  ...  full_lockdown  \\\n",
       "0                              0.000000e+00  ...              0   \n",
       "1                              0.000000e+00  ...              0   \n",
       "2                              0.000000e+00  ...              0   \n",
       "3                              0.000000e+00  ...              0   \n",
       "4                              0.000000e+00  ...              0   \n",
       "..                                      ...  ...            ...   \n",
       "606                            2.433764e-06  ...              0   \n",
       "607                            2.726988e-06  ...              0   \n",
       "608                            2.433764e-06  ...              0   \n",
       "609                            1.084931e-06  ...              0   \n",
       "610                            5.864491e-07  ...              0   \n",
       "\n",
       "     full_lockdown.l30  full_lockdown.l45  max_tp        min_tp      rain  \\\n",
       "0                  0.0                0.0  0.0000  1.650000e+00   1.65000   \n",
       "1                  0.0                0.0  0.0875  7.750000e-01   2.15625   \n",
       "2                  0.0                0.0  1.3750  2.162500e+00   0.80000   \n",
       "3                  0.0                0.0  0.4125 -1.110223e-16   0.50625   \n",
       "4                  0.0                0.0 -0.7875 -9.250000e-01   2.36250   \n",
       "..                 ...                ...     ...           ...       ...   \n",
       "606                0.0                0.0 -1.0375  8.612500e+00   4.76250   \n",
       "607                0.0                0.0 -1.6250  6.212500e+00   4.56875   \n",
       "608                0.0                0.0 -0.9250  5.450000e+00  10.87500   \n",
       "609                0.0                0.0 -0.8375  6.812500e+00   7.90000   \n",
       "610                0.0                0.0 -0.0750  5.187500e+00   3.22000   \n",
       "\n",
       "     humidity  day_of_the_week  season  trend  \n",
       "0      0.0000                0       0      1  \n",
       "1      0.0875                1       0      2  \n",
       "2      1.2875                2       0      3  \n",
       "3     -0.9625                3       0      4  \n",
       "4     -1.2000                4       0      5  \n",
       "..        ...              ...     ...    ...  \n",
       "606   -0.0500                4       3    607  \n",
       "607   -0.5875                5       3    608  \n",
       "608    0.7000                6       3    609  \n",
       "609    0.0875                0       3    610  \n",
       "610    0.7625                1       3    611  \n",
       "\n",
       "[611 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def training_and_forecasting(k,\n",
    "                data_and_time,\n",
    "                y_var,\n",
    "                functional_sets,\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Input specifications (by example):\n",
    "        forecast_horizon=3, known as $k$ in our main work.\n",
    "        Other choices include 1, 2, 5, 10.\n",
    "        data_and_time. This should be a pandas dataframe including (1) a time index, (2) the dependent variable of interest\n",
    "        and (3) exogenous variables.\n",
    "        functional_sets. This is the set of all models to be trained. It is obtained via the ModelGroupSpecs class.\n",
    "        ar_orders = [1, 2,..., 10]. For MG2T and MG3T these order run to up to 5.\n",
    "        window_sizes = [22, 63, 126, 252].\n",
    "\n",
    "    Return:\n",
    "        - The set of forecasts produced by all fixed model groups.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1 (a): Defining our indexes for training and testing.\n",
    "    T_max = len(data_and_time) - 1\n",
    "    T_train = np.arange(100, T_max+1)\n",
    "    # Logistics\n",
    "    # Creation of H_tilda\n",
    "\n",
    "    forecast_df = create_forecast_df(functional_sets)\n",
    "\n",
    "    # Step 2 (a): Training the models and making a forecast.\n",
    "    for t in tqdm(T_train, leave=True, position=0):\n",
    "\n",
    "        forecasts_t = [t]\n",
    "\n",
    "        for functional_set in functional_sets:\n",
    "            for model_group, ar_order, regressor in functional_set:\n",
    "\n",
    "                w = t-5\n",
    "\n",
    "                if model_group == 'AR':\n",
    "\n",
    "                    forecasts = train_and_forecast_MG1(data = data_and_time[y_var],\n",
    "                                                       t = t,\n",
    "                                                       w =w,\n",
    "                                                       ar_order = ar_order,\n",
    "                                                       k = k)\n",
    "\n",
    "                elif model_group == 'OLS':\n",
    "\n",
    "                    forecasts = train_and_forecast_MG2N(regressor = data_and_time[regressor],\n",
    "                                                        dep_data = data_and_time[y_var],\n",
    "                                                        t = t,\n",
    "                                                        w = w,\n",
    "                                                        k = k)\n",
    "\n",
    "                elif model_group == 'ARX':\n",
    "\n",
    "                    forecasts = train_and_forecast_MG_2T_3T(dep_data=data_and_time[y_var],\n",
    "                                                            regressor=data_and_time[regressor],\n",
    "                                                            t=t,\n",
    "                                                            w = w,\n",
    "                                                            ar_order=ar_order,\n",
    "                                                            k=k)\n",
    "\n",
    "\n",
    "        \n",
    "                forecasts_t.append(float(forecasts))\n",
    "        \n",
    "        forecast_df.loc[t] = forecasts_t\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "##### Individual Training and forecasting Functions See Appendix 1.5 and 1.6 of the pseudo-algorithm #####\n",
    "\n",
    "def train_and_forecast_MG1(data, t, w, ar_order, k):\n",
    "\n",
    "    windowed_data = np.array(data[(t - w + 1): (t + 1)])\n",
    "\n",
    "    model = ARIMA(windowed_data, order=(\n",
    "        ar_order, 0, 0), trend = 'c').fit()\n",
    "\n",
    "    forecasts = model.forecast(k)[::-1]\n",
    "\n",
    "    return forecasts[-1]\n",
    "\n",
    "\n",
    "def train_and_forecast_MG2N(regressor, dep_data, t, w, k):\n",
    "\n",
    "    forecasts = []\n",
    "\n",
    "    indep_train_data = np.array(regressor[max(0, t - w - k + 1): (t - k + 1)])\n",
    "\n",
    "    indep_train_data = sm.add_constant(indep_train_data)\n",
    "\n",
    "    dep_train_data = np.array(dep_data[max(0, t - w + 1): (t + 1)])\n",
    "\n",
    "    model = sm.OLS(dep_train_data,\n",
    "                   indep_train_data).fit()\n",
    "\n",
    "    for i in range(k):\n",
    "\n",
    "        forecasts.append(model.params[0] + model.params[1] * regressor[t - i])\n",
    "\n",
    "    return forecasts[-1]\n",
    "\n",
    "\n",
    "def train_and_forecast_MG_2T_3T(dep_data, regressor, t, w, ar_order, k):\n",
    "\n",
    "    indep_train_data = vectorise_indep_variables(dep_to_be_lagged = dep_data,\n",
    "                                                 exog=regressor,\n",
    "                                                 t=t,\n",
    "                                                 ar_order=ar_order,\n",
    "                                                 w=w,\n",
    "                                                 k=k)\n",
    "\n",
    "    dep_train_data = dep_data[max(0, t - w + 1): (t + 1)]\n",
    "\n",
    "    model = sm.OLS(dep_train_data, sm.add_constant(indep_train_data)).fit()\n",
    "\n",
    "    forecasts = forecast_with_lags(\n",
    "        model.params, dep_data, regressor, t, ar_order, k)\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "\n",
    "def vectorise_indep_variables(dep_to_be_lagged, exog, t, ar_order, w, k):\n",
    "\n",
    "    lagged_dep_data = list(dep_to_be_lagged[(t - w - ar_order): (t)])\n",
    "\n",
    "    lagged_dep_data = lagged_dep_data[::-1]\n",
    "\n",
    "    lagged_p = [lagged_dep_data[j: j+ar_order]\n",
    "                for j in range(0, len(lagged_dep_data) - ar_order)]\n",
    "\n",
    "    lagged_p = np.array(lagged_p[:: -1])\n",
    "\n",
    "    exog = np.array(exog[(t - w - k + 1): (t - k + 1)])\n",
    "\n",
    "    vectorised_training_data = np.array(\n",
    "        [np.append(lagged_p[j], [exog[j]]) for j in range(0, len(exog))])\n",
    "\n",
    "    return vectorised_training_data\n",
    "\n",
    "\n",
    "def forecast_with_lags(model_params, dep_to_be_lagged, regressor, t, ar_order, k):\n",
    "\n",
    "    forecasts = []\n",
    "\n",
    "    lagged_y = np.array(\n",
    "        dep_to_be_lagged[(t - ar_order + 1): (t + 1)])\n",
    "    lagged_x = np.array(regressor[(t - k + 1): (t + 1)])\n",
    "\n",
    "    for tau in range(0, k):  # tau = 0 means 1-step-ahead.\n",
    "\n",
    "        observations_under_consideration = [[1]]\n",
    "\n",
    "        if len(forecasts) > 0:\n",
    "            observations_under_consideration.append(\n",
    "                forecasts[::-1][:ar_order])\n",
    "\n",
    "        observations_under_consideration.append(lagged_y[tau:][::-1])\n",
    "\n",
    "        observations_under_consideration.append(lagged_x[tau].flatten())\n",
    "\n",
    "        observations_under_consideration = np.concatenate(\n",
    "            observations_under_consideration).ravel()\n",
    "\n",
    "        forecasts.append(np.dot(np.array(observations_under_consideration),\n",
    "                                np.array(model_params)))\n",
    "\n",
    "    return forecasts[-1]\n",
    "\n",
    "\n",
    "#### Helper Functions ####\n",
    "\n",
    "def naming(model_group, ar_order, regressor):\n",
    "    return f\"({model_group}, AR{ar_order}, Regressor = {regressor})\"\n",
    "\n",
    "def create_forecast_df(functional_sets):\n",
    "    headers = ['t']\n",
    "    for functional_set in functional_sets:\n",
    "        for model_group, ar_order, regressor in functional_set:\n",
    "            headers.append(naming(model_group, ar_order, regressor))\n",
    "    forecast_df = pd.DataFrame(columns=[headers])\n",
    "    return forecast_df\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# combined = combined.loc[0: 200, :]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "\n",
    "combined.rename(columns = {\"delta_cases_per_capita_United Kingdom\": \"delta_cases_per_capita_United_Kingdom\"}, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "forecasts = training_and_forecasting(1, combined, \"delta_cases_per_capita\", model_groups)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 511/511 [05:17<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "del forecasts['t']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv as rc\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "def adaptive_learning(k,\n",
    "                      data_and_time,\n",
    "                      forecast_df,\n",
    "                      y_var,\n",
    "                      functional_sets,\n",
    "                      specification_learning\n",
    "                      ):\n",
    "\n",
    "    # Loading\n",
    "    AL_specification = specification_learning[0]\n",
    "\n",
    "    if AL_specification == 'EN':\n",
    "        v, p, Lambda = specification_learning[1]\n",
    "        lambda_vector = [Lambda**(v-i) for i in range(0, v)]\n",
    "\n",
    "    # Step 1: Housekeeping.\n",
    "    # Step 1 (a):\n",
    "    T_max = len(data_and_time) - 1\n",
    "\n",
    "    # Step 1 (b): Define the training index.\n",
    "    T_train = np.arange(100,\n",
    "                        T_max)\n",
    "                        \n",
    "\n",
    "    # Step 1 (c): Define the testing index.\n",
    "    T_test = np.arange(100 + v,\n",
    "                       T_max)\n",
    "\n",
    "    forecast_errors = create_H_tilda_dict(functional_sets)\n",
    "\n",
    "    # Step 2.\n",
    "    for t in tqdm(T_train, leave=True, position=0):\n",
    "        for model_name in functional_sets:\n",
    "\n",
    "            # Step 2 (a)(i): Obtain a forecast according to the model.\n",
    "\n",
    "            forecast_value = forecast_df.loc[t, model_name]\n",
    "\n",
    "        \n",
    "            # Step 2 (a)(ii): Obtain the forecasting error.\n",
    "            val_data = data_and_time.loc[t+k, y_var]\n",
    "\n",
    "            error_t_plus_k = abs(forecast_value - val_data)\n",
    "\n",
    "            forecast_errors[model_name][t+k] = error_t_plus_k\n",
    "\n",
    "    # Step 3. Implement AL via the designated option.\n",
    "\n",
    "    if AL_specification == \"EN\":\n",
    "        optimal_models = {}\n",
    "        y_star_dict = {}\n",
    "\n",
    "    # Step 3(c).\n",
    "    for t in tqdm(T_test, leave=True, position=0):\n",
    "\n",
    "        # Step 3 (c)(i): Declare T_tilda (the adaptive learning lookback window).\n",
    "        T_tilda = np.arange(t - v + 1, t + 1)\n",
    "\n",
    "        if AL_specification == \"EN\":\n",
    "\n",
    "            y_star, h_star = regular_AL(T_tilda=T_tilda,\n",
    "                                        t=t,\n",
    "                                        AL_specification=\"EN\",\n",
    "                                        functional_sets=functional_sets,\n",
    "                                        forecast_df=forecast_df,\n",
    "                                        forecast_errors=forecast_errors,\n",
    "                                        lambda_vector=lambda_vector,\n",
    "                                        p=p)\n",
    "\n",
    "\n",
    "\n",
    "            # Step 3 (d): Save this h star (best model) and make an associated forecast\n",
    "            optimal_models.update({t: h_star})\n",
    "            y_star_dict.update({t: y_star})\n",
    "\n",
    "\n",
    "        Output = [\n",
    "            functional_sets,\n",
    "            [T_test, T_train],\n",
    "            optimal_models,\n",
    "            y_star_dict\n",
    "        ]\n",
    "\n",
    "    return Output\n",
    "\n",
    "\n",
    "def regular_AL(T_tilda,\n",
    "               t,\n",
    "               AL_specification,\n",
    "               functional_sets,\n",
    "               forecast_df,\n",
    "               forecast_errors,\n",
    "               lambda_vector,\n",
    "               p):\n",
    "\n",
    "    # Step 3 (c)(ii).\n",
    "    loss_by_model = {}\n",
    "\n",
    "    for model_name in functional_sets:\n",
    "\n",
    "        # Step 3 (c)(ii)(A): Collect the array of forecasting errors\n",
    "        # over the adaptive learning lookback window and evaluate the loss over the period T tilda.\n",
    "        errors = [forecast_errors[model_name][tau] for tau in T_tilda]\n",
    "\n",
    "        if AL_specification == \"EN\":\n",
    "            loss = exponential_learning(errors=errors, lam=lambda_vector, p=p)\n",
    "\n",
    "        loss_by_model.update({model_name: loss})\n",
    "\n",
    "    # Step 3 (c)(ii)(B): Find the argmin of the loss function for h in H over the period Tilda.\n",
    "    h_star = min(loss_by_model, key=loss_by_model.get)\n",
    "\n",
    "    # Step 3 (c)(ii)(C): Save this h star (best model) and make the associated forecast.\n",
    "    y_star = forecast_df.loc[t, h_star]\n",
    "\n",
    "    return float(y_star), h_star\n",
    "\n",
    "\n",
    "###### 1.7.1 Exponential-Norm Learning Function ######\n",
    "\n",
    "def exponential_learning(errors, lam, p):\n",
    "    e_vector = np.array(errors)\n",
    "    lambda_vector = np.array(lam)\n",
    "    loss = np.dot(np.squeeze(np.power(e_vector, p)), lambda_vector)\n",
    "    return loss\n",
    "\n",
    "##### Helper Functions ####\n",
    "\n",
    "\n",
    "def create_H_tilda_dict(H):\n",
    "    H_tilda = {}\n",
    "    for model in H:\n",
    "        H_tilda.update({model: {}})\n",
    "    return H_tilda\n",
    "\n",
    "\n",
    "def create_value_dict(H):\n",
    "    H_tilda = {}\n",
    "    for model in H:\n",
    "        H_tilda.update({model: 0})\n",
    "    return H_tilda\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "AL = adaptive_learning(1, \n",
    "                       combined, \n",
    "                       forecast_df = forecasts, \n",
    "                       y_var = 'delta_cases_per_capita', \n",
    "                       functional_sets = forecasts.columns, \n",
    "                       specification_learning= [\"EN\", [100, 2, 0.95]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 510/510 [00:04<00:00, 118.36it/s]\n",
      "100%|██████████| 410/410 [00:01<00:00, 381.96it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "preds = pd.DataFrame(AL[3], index = [i for i in AL[3].keys()]).iloc[0, :]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "full_sample = pd.DataFrame(list(AL[2].values()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "full_sample.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(ARX, AR2, Regressor = delta_cases_per_capita_United_Kingdom)       124\n",
       "(ARX, AR2, Regressor = log_new_people_vaccinated_per_capita)         84\n",
       "(ARX, AR1, Regressor = delta_cases_per_capita_United_Kingdom)        64\n",
       "(ARX, AR2, Regressor = humidity)                                     21\n",
       "(ARX, AR2, Regressor = delta_cases_per_capita_Germany)               17\n",
       "(ARX, AR2, Regressor = day_of_the_week)                              17\n",
       "(ARX, AR2, Regressor = rain)                                         15\n",
       "(ARX, AR1, Regressor = trend)                                        15\n",
       "(AR, AR2, Regressor = None)                                          13\n",
       "(ARX, AR2, Regressor = season)                                       11\n",
       "(ARX, AR2, Regressor = delta_cases_per_capita_France)                10\n",
       "(ARX, AR2, Regressor = min_tp)                                        8\n",
       "(ARX, AR2, Regressor = trend)                                         4\n",
       "(ARX, AR1, Regressor = season)                                        3\n",
       "(ARX, AR1, Regressor = humidity)                                      2\n",
       "(ARX, AR1, Regressor = log_new_people_vaccinated_per_capita)          1\n",
       "(OLS, ARNone, Regressor = delta_cases_per_capita_United_Kingdom)      1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "full_sample.value_counts().to_latex(\"Cases_full_sample.txt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "first_half = pd.DataFrame(list(AL[2].values())).loc[:len(list(AL[2].values()))/2]\n",
    "second_half = pd.DataFrame(list(AL[2].values())).loc[len(list(AL[2].values()))/2:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "first_half.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(ARX, AR2, Regressor = delta_cases_per_capita_United_Kingdom)    100\n",
       "(ARX, AR2, Regressor = humidity)                                  18\n",
       "(ARX, AR2, Regressor = delta_cases_per_capita_Germany)            17\n",
       "(AR, AR2, Regressor = None)                                       13\n",
       "(ARX, AR2, Regressor = rain)                                      13\n",
       "(ARX, AR2, Regressor = season)                                    11\n",
       "(ARX, AR2, Regressor = delta_cases_per_capita_France)              9\n",
       "(ARX, AR2, Regressor = min_tp)                                     7\n",
       "(ARX, AR1, Regressor = delta_cases_per_capita_United_Kingdom)      6\n",
       "(ARX, AR2, Regressor = day_of_the_week)                            6\n",
       "(ARX, AR1, Regressor = season)                                     3\n",
       "(ARX, AR2, Regressor = log_new_people_vaccinated_per_capita)       3\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "second_half.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(ARX, AR2, Regressor = log_new_people_vaccinated_per_capita)        82\n",
       "(ARX, AR1, Regressor = delta_cases_per_capita_United_Kingdom)       58\n",
       "(ARX, AR2, Regressor = delta_cases_per_capita_United_Kingdom)       24\n",
       "(ARX, AR1, Regressor = trend)                                       15\n",
       "(ARX, AR2, Regressor = day_of_the_week)                             11\n",
       "(ARX, AR2, Regressor = trend)                                        4\n",
       "(ARX, AR2, Regressor = humidity)                                     3\n",
       "(ARX, AR1, Regressor = humidity)                                     2\n",
       "(ARX, AR2, Regressor = rain)                                         2\n",
       "(ARX, AR1, Regressor = log_new_people_vaccinated_per_capita)         1\n",
       "(ARX, AR2, Regressor = delta_cases_per_capita_France)                1\n",
       "(ARX, AR2, Regressor = min_tp)                                       1\n",
       "(OLS, ARNone, Regressor = delta_cases_per_capita_United_Kingdom)     1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "first_half.value_counts().to_latex(\"Cases_1.txt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "second_half.value_counts().to_latex(\"Cases_2.txt\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4e7a58de4b7e505b0e82f0adcc21bb9621f61c2c1c0bdf66b0394a18a0c298a7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}